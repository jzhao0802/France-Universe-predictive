{
    "contents" : "---\ntitle: \"Delete outliers\"\nauthor: \"yan\"\ndate: \"2016-11-7\"\noutput: html_document\n---\n\n\n```{r, echo=FALSE, eval=TRUE, message=FALSE}\n\nrm(list=ls())\n\nlibrary(ggplot2)\n# library(magrittr)\nlibrary(caret)\n\nlibrary(dplyr)\n\nsetwd('D:/Project_Files2/Europe/2016/France/Universe estimation/Delete Outliers')\n\n\n# universe_sales_info <- read.csv('universe_sales_info.csv',stringsAsFactors = FALSE)\n# colnames(universe_sales_info) <- tolower(colnames(universe_sales_info))\n# \n# FR_model_data_withsurvey <- read.csv('D:/Project_Files2/Europe/2016/France/WithSurvey/001_Data/Fr_model_data_original_plus_survey_Oct29.csv', stringsAsFactors = FALSE)\n# colnames(FR_model_data_withsurvey) <- tolower(colnames(FR_model_data_withsurvey))\n\n\n# dim(universe_sales_info)\n# dim(FR_model_data_withsurvey)\n\n# save.image(\"For_Delete_outliers.RData\")\n\nload(\"For_Delete_outliers.RData\")\n\n```\n\n\n```{r, echo=FALSE, eval=TRUE, message=FALSE}\n\npanel_sales_info <- subset(universe_sales_info, !is.na(panel_catt))\n# dim(panel_sales_info)\n\nFR_model_data_withsurvey_panel <- subset(FR_model_data_withsurvey, !is.na(panel_catt_daily))\nFR_model_data_withsurvey_nonpanel <- subset(FR_model_data_withsurvey, is.na(panel_catt_daily))\n# dim(FR_model_data_withsurvey_panel)\n# dim(FR_model_data_withsurvey_nonpanel)\n\nFR_for_outliers <- subset(FR_model_data_withsurvey_panel, select = code_onekey:panel_caac_daily)\n\npre_data_for_outliers<- left_join(FR_for_outliers, panel_sales_info, by=c(\"code_onekey\"))\n# dim(pre_data_for_outliers)\n# colnames(pre_data_for_outliers)\n\n# table(apply(pre_data_for_outliers, 1, function(x){any(is.na(x))}))\n\n#step 1-- -\tKeep panelist with at least 140 days with sales, now first mark those with at least 140 days\n\npre_data_for_outliers<- mutate(pre_data_for_outliers, no_less_than_140days = ifelse(panel_nbjannuel>=140, 1, 0))\n\n#step2 -- -\tTruncate the serie regarding the share of turnover for a basket (basket / TT) or the TT turnover for total, by keeping \n# Between the 0.5th percentile and 99.5th percentile \n# From the 1st percentile only\n\ncreate_indicator_for_percentile <- function(in_df, col_name, low_p, high_p, low_p2){\n\npercentile_two_tails <- function(input_df, column_name, lower_p, higher_p){\n  \n  quantile_series <- quantile(input_df[,column_name], probs= c(lower_p, higher_p), na.rm = TRUE )\n  # print(quantile_series)\n  \n  new_column_name <- paste0(column_name, \"_between_\", lower_p, \"_\", higher_p)\n  # print(new_column_name)\n  \n  a_new_vector <- ifelse(input_df[,column_name]< quantile_series[1], 0, ifelse(input_df[,column_name] > quantile_series[2], 0, 1))\n  \n  # print(table(a_new_vector))\n  return(list(a_new_vector,new_column_name))\n\n  \n}\n\n\npercentile_one_tail <- function(input_df, column_name, lower_p){\n  \n  quantile_series <- quantile(input_df[,column_name], probs= c(lower_p), na.rm = TRUE )\n  # print(quantile_series)\n  \n  new_column_name <- paste0(column_name, \"_from_\", lower_p)\n  # print(new_column_name)\n  \n  a_new_vector<- ifelse(input_df[,column_name] < quantile_series[1], 0, 1)\n  # print(table(a_new_vector))\n  \n  return(list(a_new_vector,new_column_name))\n\n\n}\n\ns1 <- percentile_two_tails(in_df, col_name, low_p, high_p)\ns2 <- percentile_one_tail(in_df, col_name, low_p2)\n\nin_df[, s1[[2]]] <- s1[[1]]\n  \nin_df[, s2[[2]]] <- s2[[1]]\n\n  return(in_df)\n  \n}\n\n#pre_data_for_outliers2 <- create_indicator_for_percentile(pre_data_for_outliers, \"panel_catt_daily\", 0.20, 0.80, 0.01)\n# head(pre_data_for_outliers2,3)\n\n#now start the loop thru all daily variables\ndaily_ave_sales <- c(\"panel_catt_daily\", \"panel_cahm_daily\",     \"panel_cacs_daily\",     \"panel_cavt_daily\"    \n          ,\"panel_cadt_daily\",     \"panel_caft_daily\" ,    \"panel_camr_daily\" ,    \"panel_camn_daily\" ,    \"panel_caac_daily\")\n\n\nglobal_lower_p<- 0.05\nglobal_higher_p <- 1 - global_lower_p\nglobal_lower_p2 <- 0.01\n\nfor(i in 1:length(daily_ave_sales)){\n  \n  if(i==1){\n    \n  pre_data_for_outliers2<- create_indicator_for_percentile(pre_data_for_outliers, daily_ave_sales[i], global_lower_p, global_higher_p, global_lower_p2)\n  } else{\n    \n    pre_data_for_outliers2<- create_indicator_for_percentile(pre_data_for_outliers2, daily_ave_sales[i], global_lower_p, global_higher_p, global_lower_p2)\n    \n  }\n  \n}\n\n# colnames(pre_data_for_outliers2)\n\n#table(pre_data_for_outliers2$panel_catt_daily_between_0.005_0.995, pre_data_for_outliers2$panel_cahm_daily_between_0.005_0.995)\n\n# table(pre_data_for_outliers2$panel_catt_daily_from_0.01, pre_data_for_outliers2$panel_cahm_daily_from_0.01)\n# table(pre_data_for_outliers2$panel_camn_daily_between_0.005_0.995,  pre_data_for_outliers2$panel_caac_daily_between_0.005_0.995)\n# with(pre_data_for_outliers2, table(no_less_than_140days, panel_catt_daily_between_0.005_0.995))\n# with(pre_data_for_outliers2, table(panel_catt_daily_between_0.005_0.995, panel_catt_daily_from_0.01))\n\n\n\n```\n\n\n```{r, echo=FALSE, eval=TRUE, message=FALSE}\n\nfilter_out_records<- function(in_df, model_data, bucket_name, low_p, high_p){\n  \n  col_name <- paste0(bucket_name, \"_between_\", low_p, \"_\", high_p)\n  pharma_ids_to_keep <- in_df[ in_df[, col_name] == 1 & in_df[,\"no_less_than_140days\"]== 1 , \"code_onekey\"]\n  \n\n  output<-model_data[model_data[, \"code_onekey\"] %in% pharma_ids_to_keep, ]\n  cat(\"Number of panel pharmacies retained...\\n\")\n  print(nrow(output))\n  return(output)\n  \n}\n\n cal_rsquare<- function(y, y_hat){\n  \n  SST <- sum((y-mean(y))^2)\n  SSE <- sum((y-y_hat)^2)\n  R_Square<- 1-  SSE/SST\n  return(R_Square)\n  \n }   \n\n\n# prepare model variables list\n  modelData<- FR_model_data_withsurvey_panel\n  dropVars <- c(\"code_onekey\",\"panel\")\n  id_var <- \"code_onekey\"\n  \n  \n  # variables for normal model \n  vars <- setdiff(names(modelData), \n                  c(dropVars,\n                    names(modelData)[grep(\"log_|lg_\", names(modelData))]))\n  \n  var_response <- vars[grep(\"panel_\", vars)]\n  vars <- setdiff(vars, var_response)\n  # cat(\">>> There are\", length(vars), \"Variables for model <<<\\n\")\n  \n  log_vars <- c(names(modelData)[grep(\"log_|lg_|dummy\", names(modelData))])\n  \n  log_var_response <- log_vars[grep(\"log_panel_\", log_vars)]  \n  \n  log_vars <- setdiff(log_vars, log_var_response)\n  # cat(\">>> There are\", length(log_vars), \"Variables for log model <<<\\n\")  \n\n\nrun_stepwise_total <- function(in_data, market_name, lower_p, upper_p, standardized = TRUE ,log_log_model=FALSE){\n  \n  # cat(\"input data dimension...\\n\")\n  # print(dim(in_data))\n  #filter out\n  # cat(\"filter out input data...\\n\")\n  model_data <- filter_out_records(pre_data_for_outliers2, in_data, market_name, lower_p, upper_p)\n  # cat(\"filtering out completed. \\n\")\n  \n  # cat(\"model data dimension after been filtered out...\\n\")\n  # print(dim(model_data))\n  #print(colnames(model_data))\n  \n  #key variables selection according to model type, and standardize them if standardized=TRUE\n  if(log_log_model){\n    x<- model_data[ , log_vars]\n    y<- model_data[ , paste0(\"log_\", market_name)]\n\n  } else{\n    x<- model_data[ , vars]\n    y<- model_data[ , market_name]\n  }\n  \n  #check if any 0 variance--\n\n  ss <- which(apply(x, 2, function(m) sd(m)) == 0)\n  if(length(ss)>0){ \n    # cat(\"These predictors have 0 variance...\\n\")\n    # print(colnames(x)[ss])\n    \n    feature_zero_variance <- colnames(x)[ss]\n    \n    x<- x[ , setdiff(colnames(x), feature_zero_variance)]\n    \n    }\n  # stopifnot( apply(x, 2, function(m) sd(m)) != 0 )  \n  \n  if(standardized){\n    \n    x_standard <- scale(x, center = TRUE, scale = TRUE)\n    y_standard <- scale(y, center = TRUE, scale = TRUE)\n    \n    # x_mean <- apply(X_train2,2,mean, na.rm=TRUE)\n    # X_std <- apply(X_train2,2, sd, na.rm=TRUE)\n    \n    y_mean <- mean(y, na.rm=TRUE)\n    y_std <- sd(y, na.rm=TRUE)\n    \n    training_data <- data.frame(x_standard, y = y_standard)\n    \n  } else{\n    \n    training_data <- data.frame(x, y = y)\n  }\n\n            \n    lm_model <- lm(y~., data = training_data)\n\n    lm_step <- step(lm_model, \n                    direction = \"both\",\n                    trace = 0)\n\n    y_pred <- predict(lm_step, training_data)  \n \n    if(standardized){\n      \n      y_pred <-  y_pred * y_std + y_mean\n      \n    }\n    \n    if(log_log_model){\n      \n      y_pred <- exp(y_pred) - 1\n      \n      y <- exp(y) - 1\n    }\n  \n cal_rsquare<- function(y, y_hat){\n  \n  SST <- sum((y-mean(y))^2)\n  SSE <- sum((y-y_hat)^2)\n  R_Square<- 1-  SSE/SST\n  return(R_Square)\n  \n }   \n \nR.Square <- cal_rsquare(y, y_pred)\n# print(R.Square)\n#residual analysis\nstudentized_residuals <- rstudent(lm_step)\ndata_for_residual_analysis <- data.frame(Observed= y, Predicted = y_pred, Residuals = y - y_pred, Studentized_Residuals = studentized_residuals )\n\nreturn(list(data_for_residual_analysis, R.Square))\n\n}\n\n```\n\n\n\n```{r, echo=FALSE, eval=FALSE, message=FALSE}\n\nmarket_name<-  \"panel_cavt_daily\"\n\nstepwise_model_out_put <- run_stepwise_total(modelData, market_name , global_lower_p, global_higher_p, standardized = TRUE ,log_log_model= TRUE)\n\ndata_for_residual_analysis <- stepwise_model_out_put[[1]]\ncat(\"RSquare:\\n\")\nprint(stepwise_model_out_put[[2]])\n\n# plot 1 \n# -\tX = Observed vs Y = Residual \nplot_title_1 <- paste0(\"Residual V.S. Observed Y (\", market_name,\"), with Survey variables\")\nggplot(data_for_residual_analysis , aes(x= Observed, y= Residuals)) +  geom_point() + ggtitle(plot_title_1)\n\n\n# plot 2\n# -\tX = Observed vs Y = RStudent\nplot_title_2 <- paste0(\"Studentized Residuals V.S. Observed Y (\", market_name,\"), with Survey variables\")\nggplot(data_for_residual_analysis , aes(x= Observed, y= Studentized_Residuals)) +  geom_point() + ggtitle(plot_title_2)\n\n# plot 3\n# -\tX = Observed vs Y = Predicted\nplot_title_3 <- paste0(\"Predicted Y V.S. Observed Y (\", market_name,\"), with Survey variables\")\nggplot(data_for_residual_analysis , aes(x= Observed, y= Predicted)) +  geom_point() + ggtitle(plot_title_3)\n\n# plot 4\n# -\tX = Predicted vs Y = Residual \nplot_title_4 <- paste0(\"Residual V.S. Predicted Y (\", market_name,\"), with Survey variables\")\nggplot(data_for_residual_analysis , aes(x= Predicted, y= Residuals)) +  geom_point() + ggtitle(plot_title_4)\n\n\n# plot 5\n# -\tX = Predicted vs Y = RStudent \nplot_title_5 <- paste0(\"Studentized Residuals V.S. Predicted Y (\", market_name,\"), with Survey variables\")\nggplot(data_for_residual_analysis , aes(x= Predicted, y= Studentized_Residuals)) +  geom_point() + ggtitle(plot_title_5)\n\n# plot 6\n# -\tX = Leverage vs Y = RStudent  ???\n\n```\n\n\n```{r, echo=FALSE, eval=FALSE, message=FALSE}\n\ntest_model <- lm(panel_catt_daily ~ survey_counttitular + survey_countadjoint + survey_countprepar + survey_countseller\n                 + survey_countsellercosmetics + log_survey_surface + log_survey_hweeks, modelData)\n\n\ntest_y_pred <- predict(test_model, modelData)\ntest_student_residual<- rstudent(test_model)\ntest_plot <- data.frame(y=modelData[,\"panel_catt_daily\"], yred= test_y_pred, student_residual = test_student_residual )\nggplot( test_plot , aes(x= y, y= student_residual)) +  geom_point() + ggtitle(\"Studentized Residual V.S. Actual Y, with Survey variables\")\n\n\n```\n\n\n\n```{r, echo=FALSE, eval=TRUE, message=FALSE}\n\n#check pearson correlation between sales baskets and original variables.\n# modelData[ , ]\n# market_name2<- \"panel_catt_daily\"\ncorrelation_criterion <- 0.95\n\n\nfor(market_name2 in daily_ave_sales){\ndata_after_filtered<- filter_out_records(pre_data_for_outliers2, modelData, market_name2,global_lower_p, global_higher_p)\ndata_after_filtered<- data_after_filtered[,c(market_name2, vars)]\nmarket_sales <- data_after_filtered[,market_name2]\ndata_after_filtered<- data_after_filtered[,vars]\n\n# dim(data_after_filtered)\nnon_zero_vars <- nearZeroVar(data_after_filtered, saveMetrics= TRUE)\n# print(non_zero_vars)\n\n# vars_to_filter_1 <- colnames(data_after_filtered)[non_zero_vars$zeroVar]\n# print(vars_to_filter_1)\n\ndata_after_filtered <- data_after_filtered[, !non_zero_vars$zeroVar]\n# dim(data_after_filtered)\n\ndescrCor <-  cor(data_after_filtered)\nhighCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > correlation_criterion)\n# print(highCorr)\n# summary(descrCor[upper.tri(descrCor)])\n\nhighlyCorDescr <- findCorrelation(descrCor, cutoff = correlation_criterion)\n# print(colnames(data_after_filtered)[highlyCorDescr])\n# s <- cor(data_after_filtered[,highlyCorDescr])\n# write.csv(s,\"high_correlation.csv\")\n\ndata_after_filtered <- data_after_filtered[,-highlyCorDescr]\ndescrCor2 <- cor(data_after_filtered)\n# summary(descrCor2[upper.tri(descrCor2)])\n# dim(data_after_filtered)\n\n\ncomboInfo <- findLinearCombos(as.matrix(data_after_filtered))\n# print(comboInfo)\n\ndata_after_filtered <- data_after_filtered[, -comboInfo$remove]\n# dim(data_after_filtered)\n\n#draw graphics for t\n\ndata_after_filtered<- data.frame(y = market_sales,data_after_filtered)\n\n#TEST STEPWISE MODEL AFTER DELETING SOME PREDICTORS\n\nlm_model <- lm(y~., data = data_after_filtered)\n\nlm_step <- step(lm_model, \n                direction = \"both\",\n                trace = 0)\n\ny_pred <- predict(lm_step, data_after_filtered)  \n\n \nR.Square <- cal_rsquare(data_after_filtered$y, y_pred)\n\ncat('RSquare for ', market_name2, ' = ', R.Square, '\\n',file=\"RSquare_check.txt\", sep=' ', append=TRUE)\n\ndata_for_check <-   data_after_filtered[,-grep(\"dummy\", colnames(data_after_filtered))]\n\n#start drawing scattered plots.\n\ncol_names<- colnames(data_for_check)\n\n# print(colnames(data_for_check)[-1])\n# for(i in 2:ncol(data_for_check)){\n# plot_title_1 <- paste0(\"Observed Y (\", market_name2, \") V.S. \", colnames(data_for_check)[i])\n# print(ggplot(data_for_check, aes_string(x=col_names[i], y = col_names[1])) + geom_point() + ggtitle(plot_title_1) )\n# }\n\n#print correlation of sales against other predictors.\ncheck_corr <- cor(x=data_for_check[,-1], y = data_for_check[,1])\ncolnames(check_corr) <- market_name2\ncheck_corr2 <- check_corr[order(abs(check_corr[,market_name2]), decreasing = TRUE), , drop = FALSE]\ncolnames(check_corr2) <- market_name2\nwrite.csv(check_corr2, paste0(market_name2, \"_corr.csv\"),row.names=TRUE)\n\n}\n\nfor(market_name2 in daily_ave_sales){\n  \n  temp_data <- read.csv(paste0(market_name2,'_corr.csv'), stringsAsFactors = FALSE)\n  \n  temp_data$Var_Name<- temp_data$X\n  row.names(temp_data) <-NULL\n  temp_data<- temp_data[,c(\"Var_Name\",market_name2)]\n  \n  if(market_name2 == daily_ave_sales[1]){\n    merged_data <-temp_data\n  } else{\n    \n    merged_data <- full_join(merged_data, temp_data, by = c(\"Var_Name\"))\n  }\n  \n}\n\nwrite.csv(merged_data, \"merged_pearson_coef.csv\")\n\n```\n\n",
    "created" : 1479364925618.000,
    "dirty" : false,
    "encoding" : "ISO8859-1",
    "folds" : "",
    "hash" : "2842564599",
    "id" : "B3322D69",
    "lastKnownWriteTime" : 1478859250,
    "path" : "C:/work/working materials/Fr_univ_estimation/fromYan/for Jie/Delete outliers for plots only.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "type" : "r_markdown"
}